import pandas as pd
import os
import glob
import pickle
from config import DATA_DIR

class DatabaseManager:
    def __init__(self):
        self.data_dir = DATA_DIR
        self.pop_df = None
        self.tax_df = None
        self.mrt_df = None
        self.rent_df = None
        self.is_loaded = False

    def load_data_lazily(self):
        """
        Loads data only when needed, or in background.
        Uses pickle cache to speed up subsequent reloads.
        """
        if self.is_loaded:
            return

        cache_file = os.path.join(self.data_dir, "db_cache.pkl")
        
        # Try load from cache
        if os.path.exists(cache_file):
            print("âš¡ ç™¼ç¾å¿«å–æª”æ¡ˆï¼Œæ­£åœ¨å¿«é€Ÿè¼‰å…¥è³‡æ–™åº«...")
            try:
                with open(cache_file, 'rb') as f:
                    data = pickle.load(f)
                    self.pop_df = data['pop']
                    self.tax_df = data['tax']
                    self.mrt_df = data['mrt']
                    self.rent_df = data['rent']
                self.is_loaded = True
                print(f"âœ… è³‡æ–™åº«è¼‰å…¥å®Œæˆ (ä¾†è‡ªå¿«å–)")
                return
            except Exception as e:
                print(f"å¿«å–è¼‰å…¥å¤±æ•—ï¼Œå°‡é‡æ–°è®€å–åŸå§‹æª”: {e}")

        print("ğŸ“¥ æ­£åœ¨è®€å–åŸå§‹ Excel æª”æ¡ˆ (é¦–æ¬¡åŸ·è¡Œéœ€ç´„ 10-20 ç§’)...")
        
        # 1. Population
        try:
            pop_file = os.path.join(self.data_dir, "113å¹´å…¨å°å„æ‘é‡Œæ€§åˆ¥äººå£çµ±è¨ˆ.xlsx")
            if os.path.exists(pop_file):
                self.pop_df = pd.read_excel(pop_file)
                self.pop_df.columns = self.pop_df.columns.str.strip()
                print(f"ğŸ“Š [Pop DF Columns]: {list(self.pop_df.columns)}")
        except Exception as e: print(f"Pop Load Error: {e}")

        # 2. Tax
        try:
            tax_file = os.path.join(self.data_dir, "111å¹´åº¦ç¶œç¨…æ‰€å¾—æ‡‰ç´ç¨…é¡åŠç¨…ç‡å„ç¸£å¸‚ç”³å ±çµ±è¨ˆè¡¨ (2).xlsx")
            if os.path.exists(tax_file):
                self.tax_df = pd.read_excel(tax_file)
                self.tax_df.columns = self.tax_df.columns.str.strip()
                print(f"ğŸ“Š [Tax DF Columns]: {list(self.tax_df.columns)}")
        except Exception as e: print(f"Tax Load Error: {e}")

        # 3. MRT
        try:
            mrt_file = os.path.join(self.data_dir, "202510å„ç«™é€²å‡ºé‡çµ±è¨ˆ.xlsx")
            if os.path.exists(mrt_file):
                self.mrt_df = pd.read_excel(mrt_file)
        except: pass
            
        # 4. Rent (All files)
        rent_files = glob.glob(os.path.join(self.data_dir, "å…¨å°ç§Ÿé‡‘*.xls*"))
        rent_frames = []
        for rf in rent_files:
            try:
                # Use engine='openpyxl' for xlsx, default/xlrd for xls
                # To be safe with generic read_excel
                df = pd.read_excel(rf)
                # Keep only necessary columns to save memory/time if possible
                # But headers might vary, so keep all for now
                rent_frames.append(df)
            except: pass
        
        if rent_frames:
            self.rent_df = pd.concat(rent_frames, ignore_index=True)
            self.rent_df.columns = self.rent_df.columns.str.strip()

        self.is_loaded = True
        print(f"âœ… è³‡æ–™åº«è¼‰å…¥å®Œæˆ. ç§Ÿé‡‘ç­†æ•¸: {len(self.rent_df) if self.rent_df is not None else 0}")
        
        # Save cache
        try:
            with open(cache_file, 'wb') as f:
                pickle.dump({
                    'pop': self.pop_df,
                    'tax': self.tax_df,
                    'mrt': self.mrt_df,
                    'rent': self.rent_df
                }, f)
            print("ğŸ’¾ å·²å»ºç«‹å¿«å–æª”æ¡ˆ db_cache.pkl (ä¸‹æ¬¡å•Ÿå‹•å°‡ç§’é–‹)")
        except Exception as e:
            print(f"âš ï¸ ç„¡æ³•å»ºç«‹å¿«å–: {e}")

    def get_village_data(self, city, district, village, mrt_station_name=None):
        if not self.is_loaded: self.load_data_lazily()
        
        result = {
            "Population": 0, "Male_Pop": 0, "Female_Pop": 0,
            "Tax_Payers": 0, "Income_Median": 0,
            "MRT_Station": mrt_station_name, "MRT_Flow": 0,
            "Rent_1F_Avg": 0, "Rent_Upper_Avg": 0, "Rent_Advice": "" 
        }
        
        norm_city = city.replace('å°', 'è‡º') if city else ""

        # Logic same as before, just ensuring loaded
        if self.pop_df is not None:
            try:
                # 1. Normalize Inputs
                search_city = norm_city
                search_dist = district.strip()
                search_village = village.strip()
                
                print(f"ğŸ” [DB Debug] æœå°‹ç›®æ¨™: {search_city} | {search_dist} | {search_village}")

                # 2. Filter Population (Columns: ['å€åŸŸåˆ¥', 'æ‘é‡Œåç¨±', 'å¥³', 'ç”·', 'ç¸½äººå£'])
                # 'å€åŸŸåˆ¥' likely contains "City District" e.g. "è‡ºåŒ—å¸‚æ¾å±±å€" or just "æ¾å±±å€" depending on source.
                # We will use string contain search on 'å€åŸŸåˆ¥' for both City and District to be safe.
                
                df = self.pop_df.astype(str)
                
                # Loose Match Strategy:
                # Check if 'å€åŸŸåˆ¥' contains "District" AND ("City" OR is implicit)
                # Usually 'å€åŸŸåˆ¥' is uniquely identifying like 'æ–°åŒ—å¸‚æ¿æ©‹å€'
                
                keywords = [search_dist]
                if len(search_city) > 2: keywords.append(search_city[-2:]) # "åŒ—å¸‚"
                
                # Custom mask builder
                loc_mask = df['å€åŸŸåˆ¥'].apply(lambda x: all(k in x for k in keywords))
                
                # Village Match
                village_mask = df['æ‘é‡Œåç¨±'] == search_village
                
                q = df[loc_mask & village_mask]
                
                # Retry Fuzzy Village
                if q.empty and len(search_village) > 2:
                     short_village = search_village.replace("é‡Œ", "").replace("æ‘", "")
                     village_mask_fuzzy = df['æ‘é‡Œåç¨±'].str.contains(short_village)
                     q = df[loc_mask & village_mask_fuzzy]

                if not q.empty:
                    row = q.iloc[0]
                    m = int(float(row.get('ç”·', 0))) # Column is 'ç”·'
                    f = int(float(row.get('å¥³', 0))) # Column is 'å¥³'
                    result['Population'] = m + f
                    result['Male_Pop'] = m
                    result['Female_Pop'] = f
                    print(f"âœ… [DB Success] æ‰¾åˆ°äººå£æ•¸æ“š: {result['Population']} äºº")
                else:
                    print(f"âš ï¸ [DB Warning] æ‰¾ä¸åˆ°äººå£æ•¸æ“š (æœå°‹: {search_city}{search_dist} - {search_village})")

            except Exception as e: 
                print(f"âŒ [DB Error] Population lookup failed: {e}")

        if self.tax_df is not None:
            try:
                # Tax Columns: ['ç¸£å¸‚åˆ¥', 'æ‘é‡Œ', 'ç´ç¨…å–®ä½(æˆ¶)', 'ç¶œåˆæ‰€å¾—ç¸½é¡', 'å¹³å‡æ•¸', 'ä¸­ä½æ•¸'...]
                df = self.tax_df.astype(str)
                
                search_city_short = norm_city.replace("å°", "").replace("è‡º", "")
                
                # Filter
                if not search_village:
                    print("âš ï¸ [DB Debug] æ‘é‡Œåç¨±ç‚ºç©ºï¼Œè·³éç´ç¨…æŸ¥è©¢ä»¥é¿å…èª¤åˆ¤")
                else:
                    # Proceed with tax lookup only if village exists
                    city_mask = df['ç¸£å¸‚åˆ¥'].str.contains(search_city_short)
                    # Tax file often splits City/District or merges them? 
                    # If 'è¡Œæ”¿å€' column is MISSING (as seen in logs), then 'ç¸£å¸‚åˆ¥' or 'æ‘é‡Œ' might contain it?
                    # Actually logs showed: ['ç¸£å¸‚åˆ¥', 'æ‘é‡Œ', 'ç´ç¨…å–®ä½(æˆ¶)'...] -> WHERE IS DISTRICT?
                    # Maybe 'æ‘é‡Œ' contains "District Village"? Or 'ç¸£å¸‚åˆ¥' contains "City District"?
                    # Let's try matching District in 'ç¸£å¸‚åˆ¥' OR 'æ‘é‡Œ' just to be safe.
                    # Actually standard MOF tax data usually has "ç¸£å¸‚", "è¡Œæ”¿å€", "æ‘é‡Œ". 
                    # If only "ç¸£å¸‚åˆ¥" corresponds to City? And maybe "è¡Œæ”¿å€" is missing from print?
                    # Wait, User logs: ['ç¸£å¸‚åˆ¥', 'æ‘é‡Œ', 'ç´ç¨…å–®ä½(æˆ¶)'...] -> It seems District column is named something else or missing!
                    # Ah, standard file often has "è¡Œæ”¿å€åˆ¥" or merged. 
                    # Let's assume 'ç¸£å¸‚åˆ¥' might be 'æ–°åŒ—å¸‚æ¿æ©‹å€' or we search district in 'æ‘é‡Œ' (unlikely).
                    # Let's try searching District in 'ç¸£å¸‚åˆ¥' first (common in some files).
                    
                    dist_mask = df['ç¸£å¸‚åˆ¥'].str.contains(search_dist) | df['æ‘é‡Œ'].str.contains(search_dist)
                    
                    village_mask = df['æ‘é‡Œ'] == search_village
                    
                    q = df[city_mask & dist_mask & village_mask]
                    
                    if q.empty:
                         short_village = search_village.replace("é‡Œ", "").replace("æ‘", "")
                         village_mask_fuzzy = df['æ‘é‡Œ'].str.contains(short_village)
                         q = df[city_mask & dist_mask & village_mask_fuzzy]

                    if not q.empty:
                        row = q.iloc[0]
                        result['Tax_Payers'] = int(float(row.get('ç´ç¨…å–®ä½(æˆ¶)', 0)))
                        result['Income_Median'] = float(row.get('ä¸­ä½æ•¸', 0))
                        print(f"âœ… [DB Success] æ‰¾åˆ°ç´ç¨…æˆ¶æ•¸: {result['Tax_Payers']}")
                    else:
                        print(f"âš ï¸ [DB Warning] æ‰¾ä¸åˆ°ç´ç¨…æ•¸æ“š")
            except Exception as e:
                print(f"âŒ [DB Error] Tax lookup failed: {e}")

        if self.mrt_df is not None and mrt_station_name:
            clean_station = mrt_station_name.replace("æ·é‹", "").replace("ç«™", "")
            try:
                match_row = self.mrt_df[self.mrt_df.iloc[:, 0].astype(str).str.contains(clean_station)]
                if not match_row.empty:
                    row = match_row.iloc[0]
                    numeric_cols = row[pd.to_numeric(row, errors='coerce').notnull()]
                    if len(numeric_cols) > 0:
                        result['MRT_Flow'] = int(numeric_cols.sum())
            except: pass

        return result

    def get_rental_analysis(self, city, district, address_road):
        if not self.is_loaded: self.load_data_lazily()
        
        stats = {
            "1F_Count": 0, "1F_Min": 0, "1F_Max": 0, "1F_Avg": 0,
            "Upper_Count": 0, "Upper_Avg": 0,
            "Estimated_Range": "ç„¡æ•¸æ“š",
            "Data_Source_Count": 0
        }
        
        if self.rent_df is None or self.rent_df.empty:
            return stats

        try:
            # Filter Logic (Simpified for brevity, assume Logic from previous step)
            # 1. District
            mask = (self.rent_df['é„‰é®å¸‚å€'] == district)
            df_dist = self.rent_df[mask].copy()
            if df_dist.empty: return stats

            # 2. Price/Ping
            price_col = 'ç¸½é¡å…ƒ' if 'ç¸½é¡å…ƒ' in df_dist.columns else 'å–®åƒ¹å…ƒå¹³æ–¹å…¬å°º'
            area_col = 'å»ºç‰©ç¸½é¢ç©å¹³æ–¹å…¬å°º'
            df_dist = df_dist[df_dist[area_col] > 0]
            df_dist['Price_Per_Ping'] = df_dist[price_col] / (df_dist[area_col] * 0.3025)

            # 3. Road
            addr_col = 'åœŸåœ°å€æ®µä½ç½®å»ºç‰©å€æ®µé–€ç‰Œ'
            if address_road:
                df_road = df_dist[df_dist[addr_col].astype(str).str.contains(address_road)].copy()
                final_df = df_road if len(df_road) >= 3 else df_dist
            else:
                final_df = df_dist

            stats['Data_Source_Count'] = len(final_df)
            
            # 4. Floor
            floor_col = 'ç§»è½‰å±¤æ¬¡'
            mask_1f = final_df[floor_col].astype(str).str.contains('ä¸€å±¤|1å±¤')
            df_1f = final_df[mask_1f]
            df_upper = final_df[~mask_1f]

            if not df_1f.empty:
                prices = df_1f['Price_Per_Ping']
                stats['1F_Count'] = len(df_1f)
                stats['1F_Avg'] = int(prices.mean())
            
            if not df_upper.empty:
                prices = df_upper['Price_Per_Ping']
                stats['Upper_Count'] = len(df_upper)
                stats['Upper_Avg'] = int(prices.mean())

            # 5. Advice
            if stats['1F_Count'] >= 3:
                low = int(df_1f['Price_Per_Ping'].quantile(0.25))
                high = int(df_1f['Price_Per_Ping'].quantile(0.75))
                stats['Estimated_Range'] = f"{low} ~ {high}"
            elif stats['Upper_Count'] > 0:
                est = int(stats['Upper_Avg'] * 1.6)
                stats['Estimated_Range'] = f"{int(est*0.9)} ~ {int(est*1.1)} (æ¨ä¼°)"
        except Exception as e:
            print(f"Error in rent analysis: {e}")

        return stats
